{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('admission_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          500 non-null    int64  \n",
      " 1   TOEFL Score        500 non-null    int64  \n",
      " 2   University Rating  500 non-null    int64  \n",
      " 3   SOP                500 non-null    float64\n",
      " 4   LOR                500 non-null    float64\n",
      " 5   CGPA               500 non-null    float64\n",
      " 6   Research           500 non-null    int64  \n",
      " 7   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 0:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 7), (100, 7))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train_scaled = scale.fit_transform(x_train)\n",
    "x_test_scaled = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_dim = 7))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1374 - val_loss: 0.1108\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1022 - val_loss: 0.0735\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0661 - val_loss: 0.0452\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402 - val_loss: 0.0271\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0207 - val_loss: 0.0188\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0173 - val_loss: 0.0160\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0147\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0104\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer='Adam')\n",
    "\n",
    "hist = model.fit(x_train_scaled, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "ypre = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4982314126191655"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, ypre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## performance could be better, so we should add more layers to the ANN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_dim = 7))\n",
    "model.add(Dense(7, activation='relu', ))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.5900 - val_loss: 0.3316\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2876 - val_loss: 0.1212\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1006 - val_loss: 0.0344\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0369 - val_loss: 0.0170\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0288 - val_loss: 0.0169\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0290 - val_loss: 0.0150\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0269 - val_loss: 0.0130\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0223 - val_loss: 0.0111\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - val_loss: 0.0098\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0160 - val_loss: 0.0087\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - val_loss: 0.0080\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0074\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0064\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0113 - val_loss: 0.0056\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0051\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0050\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0045\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0042\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer='Adam')\n",
    "\n",
    "hist = model.fit(x_train_scaled, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7788369341644459"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypre = model.predict(x_test_scaled)\n",
    "\n",
    "r2_score(y_test, ypre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training and the validation loss\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
